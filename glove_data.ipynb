{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from model_arch import *\n",
    "import csv, sys, pdb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rigid_accel2 = \"/home/togzhan/sample/data/rigid_accel2.csv\"\n",
    "file_rigid_accel = \"/home/togzhan/sample/data/rigid_accel.csv\"\n",
    "file_rigid_pressure = \"/home/togzhan/sample/data/rigid_pressure.csv\"\n",
    "file_rigid_imu = \"/home/togzhan/sample/data/rigid_imu.csv\"\n",
    "\n",
    "\n",
    "file_soft_accel2 = \"/home/togzhan/sample/data/soft_accel2.csv\"\n",
    "file_soft_accel = \"/home/togzhan/sample/data/soft_accel.csv\"\n",
    "file_soft_pressure = \"/home/togzhan/sample/data/soft_pressure.csv\"\n",
    "file_soft_imu = \"/home/togzhan/sample/data/soft_imu.csv\"\n",
    "\n",
    "df_accel2_rigid = pd.read_csv(file_rigid_accel2, sep = ',', header = None)\n",
    "df_accel_rigid = pd.read_csv(file_rigid_accel, sep = ',', header = None)\n",
    "df_pressure_rigid = pd.read_csv(file_rigid_pressure, sep = ',', header = None)\n",
    "df_imu_rigid = pd.read_csv(file_rigid_imu, sep = ',', header = None)\n",
    "\n",
    "df_accel2_soft = pd.read_csv(file_soft_accel2, sep = ',', header = None)\n",
    "df_accel_soft = pd.read_csv(file_soft_accel, sep = ',', header = None)\n",
    "df_pressure_soft = pd.read_csv(file_soft_pressure, sep = ',', header = None)\n",
    "df_imu_soft = pd.read_csv(file_soft_imu, sep = ',', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_the_data(df_accel2, df_pressure, df_imu, inp):\n",
    "    df_pressure_n = normalize(df_pressure)\n",
    "    dP = pd.DataFrame()\n",
    "    dA = pd.DataFrame()\n",
    "    dI = pd.DataFrame()\n",
    "    D = pd.DataFrame()\n",
    "    data = pd.DataFrame()\n",
    "    df_accelT = df_accel2.transpose()\n",
    "    df_pressure_nT = df_pressure_n.transpose()\n",
    "    df_imuT = df_imu.transpose()\n",
    "    for i in range(50):\n",
    "        P = pd.DataFrame()\n",
    "        A = pd.DataFrame()\n",
    "        I = pd.DataFrame()\n",
    "        for j in range(27):\n",
    "            p = []\n",
    "            p = df_pressure_nT.values[j, i*744:(i+1)*744]\n",
    "            P = pd.concat([P, pd.DataFrame(p)], axis = 0)\n",
    "        for j in range(200):\n",
    "            a = []\n",
    "            a = df_accelT.values[j, i*744:(i+1)*744]\n",
    "            A = pd.concat([A, pd.DataFrame(a)], axis = 0)\n",
    "        for j in range(18):\n",
    "            ii = []\n",
    "            ii = df_imuT.values[j, i*744:(i+1)*744]\n",
    "            I = pd.concat([I, pd.DataFrame(ii)], axis = 0)\n",
    "        \n",
    "        D = pd.concat([P, A, I], axis = 0)\n",
    "        \n",
    "        data = pd.concat([data, D], axis = 1)\n",
    "#         dP = pd.concat([dP, P], axis = 1)\n",
    "#         dA = pd.concat([dA, A], axis = 1)\n",
    "#         dI = pd.concat([dI, I], axis = 1)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    df_accel_rigid = df_accel_rigid.transpose()\n",
    "    df_data_s = df_data_soft.transpose()\n",
    "    df_rigid = pd.DataFrame()\n",
    "    df_soft = pd.DataFrame()\n",
    "    data = pd.DataFrame()\n",
    "    for i in range(50):\n",
    "        ddd = pd.DataFrame()\n",
    "        dd = pd.DataFrame()\n",
    "        for j in range(244):\n",
    "            a = []\n",
    "            a = df_data_r.values[j, i*744:(i+1)*744]\n",
    "            b = []\n",
    "            b = df_data_s.values[j, i*744:(i+1)*744]\n",
    "            ddd = pd.concat([ddd, pd.DataFrame(a)], axis = 0)\n",
    "            dd = pd.concat([dd, pd.DataFrame(b)], axis = 0)\n",
    "        df_rigid = pd.concat([df_rigid, ddd], axis = 1)\n",
    "        df_soft = pd.concat([df_soft, ddd], axis = 1)\n",
    "        \n",
    "    data = pd.concat([df_soft, df_rigid], axis = 1, ignore_index=True)\n",
    "    return data.transpose()\n",
    "\n",
    "# data in format 244*744 by 100 - # of traials \n",
    "df_data_all = combine(df_data_rigid, df_data_soft)\n",
    "df_data_all.columns = range(df_data_all.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "def normalize(data):\n",
    "    m = data.max()\n",
    "    data = pd.DataFrame(data)\n",
    "#     df_max = [420, 420, 420, 418, 418, 450, 432, 432, 432, 390, 472, 480, 480, 480, 435, 433, 501, 405, 400, 400, 400 ,400, 370, 455 ,444, 310, 445]\n",
    "    df_max = [450]\n",
    "    df_max = pd.DataFrame(df_max)\n",
    "    df_min = 0;\n",
    "    p = pd.DataFrame()\n",
    "    k = []\n",
    "    for i in range(27):\n",
    "        k = np.divide(data.values[:,i].astype('float'), df_max.values[0].astype('float'))\n",
    "        k = pd.DataFrame(k)    \n",
    "        p = pd.concat([p, k], axis = 1)\n",
    "        \n",
    "    data = p\n",
    "    data = pd.DataFrame(p)\n",
    "    return data\n",
    "#######################################################\n",
    "df_pressure_rigid_n = pd.DataFrame()\n",
    "df_pressure_soft_n = pd.DataFrame()\n",
    "df_pressure_rigid_n = normalize(df_pressure_rigid)\n",
    "df_pressure_soft_n = normalize(df_pressure_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_rigid_n = df_pressure_rigid_n.transpose()\n",
    "df_pressure_rigid_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data_rigid = \"/home/togzhan/sample/data/data/data_rigid.csv\"\n",
    "data_rigid = pd.read_csv(file_data_rigid, sep = ',', header = None, index_col=None)\n",
    "\n",
    "file_data_soft = \"/home/togzhan/sample/data/data/data_soft.csv\"\n",
    "data_soft = pd.read_csv(file_data_soft, sep = ',', header = None, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_rigid = pd.DataFrame()\n",
    "df_data_soft = pd.DataFrame()\n",
    "df_data = pd.DataFrame()\n",
    "\n",
    "df_data_rigid = pd.concat([df_pressure_rigid_n, df_accel2_rigid, df_imu_rigid], axis = 1, sort = False)\n",
    "df_data_soft = pd.concat([df_pressure_soft_n, df_accel2_soft, df_imu_soft], axis = 1, sort = False)\n",
    "\n",
    "    # data in format 244 - #of feautures and 100*744\n",
    "df_data = pd.concat([df_pressure_soft_n, df_accel2_soft, df_imu_soft], axis = 1, sort = False, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data by the feautures  244 feautures\n",
    "def combine_a_i_p(a, i, p): \n",
    "    df_data = pd.DataFrame()\n",
    "    df_data = pd.concat([p, a, i], axis = 1, sort = False)\n",
    "    # data in format 244 - #of feautures and 100*744\n",
    "    return df_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(df_data_rigid, df_data_soft):\n",
    "    df_data_r = df_data_rigid.transpose()\n",
    "    df_data_s = df_data_soft.transpose()\n",
    "    df_rigid = pd.DataFrame()\n",
    "    df_soft = pd.DataFrame()\n",
    "    data = pd.DataFrame()\n",
    "    for i in range(50):\n",
    "        ddd = pd.DataFrame()\n",
    "        dd = pd.DataFrame()\n",
    "        for j in range(244):\n",
    "            a = []\n",
    "            a = df_data_r.values[j, i*744:(i+1)*744]\n",
    "            b = []\n",
    "            b = df_data_s.values[j, i*744:(i+1)*744]\n",
    "            ddd = pd.concat([ddd, pd.DataFrame(a)], axis = 0)\n",
    "            dd = pd.concat([dd, pd.DataFrame(b)], axis = 0)\n",
    "        df_rigid = pd.concat([df_rigid, ddd], axis = 1)\n",
    "        df_soft = pd.concat([df_soft, ddd], axis = 1)\n",
    "        \n",
    "    data = pd.concat([df_soft, df_rigid], axis = 1, ignore_index=True)\n",
    "    return data.transpose()\n",
    "\n",
    "# data in format 244*744 by 100 - # of traials \n",
    "df_data_all = combine(df_data_rigid, df_data_soft)\n",
    "df_data_all.columns = range(df_data_all.shape[1])\n",
    "\n",
    "######################################################\n",
    "# df_data_r = combine_data(pressure_n, accelerometer, imu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bilabel = []\n",
    "for i in range(100):\n",
    "    if(i<50):\n",
    "        df_bilabel.append(0)\n",
    "    else:\n",
    "        df_bilabel.append(1)\n",
    "df_bilabel = pd.DataFrame(df_bilabel, index=None)\n",
    "\n",
    "k = 0\n",
    "labels = []\n",
    "for i in range(100):\n",
    "    if(np.mod(i,5) == 0):\n",
    "        k = k +1\n",
    "    labels.append(k)        \n",
    "df_label = pd.DataFrame(labels, index=None)\n",
    "\n",
    "# labels - 1st number 0 or 1 0 - rigid 1 - soft, second number defines the object\n",
    "df_newlabel = df_bilabel.astype(str) + \"_\" + df_label.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data_l = pd.DataFrame()\n",
    "# df_data_l = pd.concat([df_data_all, labels], axis = 1, sort = False)\n",
    "df_data_l = pd.concat([df_data_all,df_bilabel], axis=1, sort=False)\n",
    "df_train, df_eval = train_test_split(df_data_all, test_size=1.0/3, random_state=777, stratify=df_newlabel.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data \n",
    "df_data.to_csv(path_or_buf=\"/home/togzhan/sample/data/data/df_data.csv\", index=False) \n",
    "\n",
    "df_data_all.to_csv(path_or_buf=\"/home/togzhan/sample/data/data/df_data_all.csv\", index=False) \n",
    "\n",
    "df_train.to_csv(path_or_buf=\"/home/togzhan/sample/data/data/df_train2.csv\", index=False) \n",
    "\n",
    "df_eval.to_csv(path_or_buf=\"/home/togzhan/sample/data/data/df_eval2.csv\", index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = \"/home/togzhan/sample/data/data/df_train2.csv\"\n",
    "df_eval2 = \"/home/togzhan/sample/data/data/df_eval2.csv\"\n",
    "\n",
    "df_train = pd.read_csv(df_train2, sep = ',', header = None)\n",
    "df_eval = pd.read_csv(df_eval2, sep = ',', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = torch.FloatTensor(df_train.values[:,1].astype('float64'))\n",
    "\n",
    "train_x\t= torch.FloatTensor(df_train.values[:,:-3].astype('float64'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7bed17418dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x\t= torch.FloatTensor(df_train.values[:,:-3].astype('float64'))\n",
    "print df_train.values[1,:]\n",
    "print train_x[1,:]\n",
    "\n",
    "print df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use raw features\n",
    "train_x\t= torch.FloatTensor(df_train.values[:,:-3].astype('float64'))\n",
    "test_x = torch.FloatTensor(df_eval.values[:,:-3].astype('float64'))\n",
    "\n",
    "train_y = torch.FloatTensor(df_train.values[:,-3].astype('float64'))\n",
    "test_y = torch.FloatTensor(df_eval.values[:,-3].astype('float64'))\n",
    "dtype = torch.float\n",
    "#device = torch.device(\"cpu\") # Uncomment this to run on CPU\n",
    "if len(sys.argv) > 1:\n",
    "    gpu_id=sys.argv[1]\n",
    "    device = torch.device(\"cuda:\"+gpu_id)\n",
    "else:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "print(device)\n",
    "\n",
    "epochs = 10000\n",
    "N = 16 #batch size\n",
    "D_in = train_x.shape[1]\n",
    "D_out = 1\n",
    "drop = 0.4\n",
    "#FFN Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
